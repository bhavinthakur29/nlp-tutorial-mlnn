# Sentiment Analysis Using LSTM

## Overview
This project explores **Sentiment Analysis** using **Long Short-Term Memory (LSTM)** networks, a deep learning approach for classifying text sentiment as **positive, negative, or neutral**. The tutorial covers **Natural Language Processing (NLP) techniques** such as tokenization, stopword removal, lemmatization, and word embeddings.

## Requirements
- Python
- TensorFlow/Keras
- NumPy, Pandas, Matplotlib
- NLTK for text preprocessing

## Usage
Run the Python script:
```sh
python nlp_tutorial.py
```
For detailed explanations, refer to the tutorial report included in this repository.

## Author
Bhavin Thakur (Student ID: 23079699)

## References
## References
- Goldberg, Y. (2017). **Neural Network Methods for Natural Language Processing**. *Synthesis Lectures on Human Language Technologies*. [Link](https://doi.org/10.2200/S00762ED1V01Y201703HLT037)
- Hochreiter, S., & Schmidhuber, J. (1997). **Long Short-Term Memory**. *Neural Computation, 9(8), 1735-1780*. [Link](https://doi.org/10.1162/neco.1997.9.8.1735)
- Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). **BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**. *arXiv preprint*. [Link](https://arxiv.org/abs/1810.04805)
- Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). **Distributed Representations of Words and Phrases and their Compositionality**. *Advances in Neural Information Processing Systems (NeurIPS)*. [Link](https://arxiv.org/abs/1310.4546)
- Socher, R., Perelygin, A., Wu, J., Chuang, J., Manning, C. D., Ng, A. Y., & Potts, C. (2013). **Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank**. *Conference on Empirical Methods in Natural Language Processing (EMNLP)*. [Link](https://www.aclweb.org/anthology/D13-1170/)


## License
This project is **closed-source** and **all rights are reserved**. You may not use, copy, modify, or distribute any part of this project without **explicit written permission** from the author.
